{
    "feed": {
        "@xmlns:opensearch": "http://a9.com/-/spec/opensearch/1.1/",
        "@xmlns:arxiv": "http://arxiv.org/schemas/atom",
        "@xmlns": "http://www.w3.org/2005/Atom",
        "id": "https://arxiv.org/api/GYXgOfCBQdW2qz4J20yiNWanGQo",
        "title": "arXiv Query: search_query=all:machine OR all:learning, OR all:AI, OR all:deep OR all:learning&id_list=&start=0&max_results=10",
        "updated": "2026-02-16T21:18:43Z",
        "link": {
            "@href": "https://arxiv.org/api/query?search_query=all:machine+OR+(all:learning,+OR+(all:AI,+OR+(all:deep+OR+all:learning)))&start=0&max_results=10&id_list=",
            "@type": "application/atom+xml"
        },
        "opensearch:itemsPerPage": "10",
        "opensearch:totalResults": "541116",
        "opensearch:startIndex": "0",
        "entry": [
            {
                "id": "http://arxiv.org/abs/2602.13197v1",
                "title": "Imitating What Works: Simulation-Filtered Modular Policy Learning from Human Videos",
                "updated": "2026-02-13T18:59:10Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13197v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13197v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "The ability to learn manipulation skills by watching videos of humans has the potential to unlock a new source of highly scalable data for robot learning. Here, we tackle prehensile manipulation, in which tasks involve grasping an object before performing various post-grasp motions. Human videos offer strong signals for learning the post-grasp motions, but they are less useful for learning the prerequisite grasping behaviors, especially for robots without human-like hands. A promising way forward is to use a modular policy design, leveraging a dedicated grasp generator to produce stable grasps. However, arbitrary stable grasps are often not task-compatible, hindering the robot's ability to perform the desired downstream motion. To address this challenge, we present Perceive-Simulate-Imitate (PSI), a framework for training a modular manipulation policy using human video motion data processed by paired grasp-trajectory filtering in simulation. This simulation step extends the trajectory data with grasp suitability labels, which allows for supervised learning of task-oriented grasping capabilities. We show through real-world experiments that our framework can be used to learn precise manipulation skills efficiently without any robot data, resulting in significantly more robust performance than using a grasp generator naively.",
                "category": [
                    {
                        "@term": "cs.RO",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.CV",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:59:10Z",
                "arxiv:primary_category": {
                    "@term": "cs.RO"
                },
                "author": [
                    {
                        "name": "Albert J. Zhai"
                    },
                    {
                        "name": "Kuo-Hao Zeng"
                    },
                    {
                        "name": "Jiasen Lu"
                    },
                    {
                        "name": "Ali Farhadi"
                    },
                    {
                        "name": "Shenlong Wang"
                    },
                    {
                        "name": "Wei-Chiu Ma"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13195v1",
                "title": "Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision",
                "updated": "2026-02-13T18:58:30Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13195v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13195v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., \"left-most apple\") and overlooks functional and physical reasoning (e.g., \"where can I safely store the knife?\"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/",
                "category": {
                    "@term": "cs.CV",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-13T18:58:30Z",
                "arxiv:comment": "Project webpage: https://glab-caltech.github.io/converseg/",
                "arxiv:primary_category": {
                    "@term": "cs.CV"
                },
                "author": [
                    {
                        "name": "Aadarsh Sahoo"
                    },
                    {
                        "name": "Georgia Gkioxari"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13193v1",
                "title": "Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control",
                "updated": "2026-02-13T18:57:56Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13193v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13193v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Pretrained vision-language models (VLMs) can make semantic and visual inferences across diverse settings, providing valuable common-sense priors for robotic control. However, effectively grounding this knowledge in robot behaviors remains an open challenge. Prior methods often employ a hierarchical approach where VLMs reason over high-level commands to be executed by separate low-level policies, e.g., vision-language-action models (VLAs). The interface between VLMs and VLAs is usually natural language task instructions, which fundamentally limits how much VLM reasoning can steer low-level behavior. We thus introduce Steerable Policies: VLAs trained on rich synthetic commands at various levels of abstraction, like subtasks, motions, and grounded pixel coordinates. By improving low-level controllability, Steerable Policies can unlock pretrained knowledge in VLMs, enabling improved task generalization. We demonstrate this benefit by controlling our Steerable Policies with both a learned high-level embodied reasoner and an off-the-shelf VLM prompted to reason over command abstractions via in-context learning. Across extensive real-world manipulation experiments, these two novel methods outperform prior embodied reasoning VLAs and VLM-based hierarchical baselines, including on challenging generalization and long-horizon tasks.\n  Website: steerable-policies.github.io",
                "category": {
                    "@term": "cs.RO",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-13T18:57:56Z",
                "arxiv:primary_category": {
                    "@term": "cs.RO"
                },
                "author": [
                    {
                        "name": "William Chen"
                    },
                    {
                        "name": "Jagdeep Singh Bhatia"
                    },
                    {
                        "name": "Catherine Glossop"
                    },
                    {
                        "name": "Nikhil Mathihalli"
                    },
                    {
                        "name": "Ria Doshi"
                    },
                    {
                        "name": "Andy Tang"
                    },
                    {
                        "name": "Danny Driess"
                    },
                    {
                        "name": "Karl Pertsch"
                    },
                    {
                        "name": "Sergey Levine"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13191v1",
                "title": "CoPE-VideoLM: Codec Primitives For Efficient Video Language Models",
                "updated": "2026-02-13T18:57:31Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13191v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13191v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\\%$ and token usage by up to $93\\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.",
                "category": [
                    {
                        "@term": "cs.CV",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.AI",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.CL",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:57:31Z",
                "arxiv:comment": "Project Page: https://sayands.github.io/cope/",
                "arxiv:primary_category": {
                    "@term": "cs.CV"
                },
                "author": [
                    {
                        "name": "Sayan Deb Sarkar"
                    },
                    {
                        "name": "R\u00e9mi Pautrat"
                    },
                    {
                        "name": "Ondrej Miksik"
                    },
                    {
                        "name": "Marc Pollefeys"
                    },
                    {
                        "name": "Iro Armeni"
                    },
                    {
                        "name": "Mahdi Rad"
                    },
                    {
                        "name": "Mihai Dusmanu"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13190v1",
                "title": "Disorder viscosity correction approach to calculate spinodal temperature and wavelength",
                "updated": "2026-02-13T18:56:21Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13190v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13190v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    },
                    {
                        "@rel": "related",
                        "@href": "https://doi.org/10.1016/j.actamat.2026.121983",
                        "@title": "doi"
                    }
                ],
                "summary": "Spinodal decomposition, a key mechanism to microstructure formation in materials, has long posed challenges for predictive modeling, due to the need for parameter-free approaches that accurately capture local energy landscapes. In this work, we propose an approach to predict spinodal behavior by introducing a disorder viscosity correction to bulk free energies computed from finite, small, representative cells. We approximate the energy penalty required to transition into a disordered state to enable the stabilization of locally concave bulk free energy regions - essential for interface formation - while suppressing long-range concentration fluctuations. This approximation circumvents the complexity of full ab initio parameterization of interfacial properties and is well-suited for high-throughput and machine-learning frameworks. Our approach captures the necessary physics underpinning spinodal kinetics, offering a scalable route to predict spinodal regions in compositionally complex and high-entropy materials.",
                "category": {
                    "@term": "cond-mat.mtrl-sci",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-13T18:56:21Z",
                "arxiv:comment": "16 pages, 6 pictures",
                "arxiv:primary_category": {
                    "@term": "cond-mat.mtrl-sci"
                },
                "arxiv:journal_ref": "Acta Mater. (2026) 10.1016/j.actamat.2026.121983",
                "author": [
                    {
                        "name": "Simon Divilov"
                    },
                    {
                        "name": "Hagen Eckert"
                    },
                    {
                        "name": "Nico Hotz"
                    },
                    {
                        "name": "Xiomara Campilongo"
                    },
                    {
                        "name": "Stefano Curtarolo"
                    }
                ],
                "arxiv:doi": "10.1016/j.actamat.2026.121983"
            },
            {
                "id": "http://arxiv.org/abs/2602.13187v1",
                "title": "Nuclear gradients from auxiliary-field quantum Monte Carlo and their application in geometry optimization and transition state search",
                "updated": "2026-02-13T18:53:55Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13187v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13187v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "In this article, we present a method for computing accurate and scalable nuclear forces within the phaseless auxiliary-field quantum Monte Carlo (AFQMC) framework. Our approach leverages automatic differentiation of the energy functional to obtain nuclear gradients at a computational cost comparable to that of energy evaluation. The accuracy of the method is validated against finite difference calculations, showing excellent agreement. We then explore several machine learning (ML) strategies for learning noisy AFQMC data. These ML potentials are subsequently used to perform geometry optimizations and nudged elastic band (NEB) calculations, successfully identifying the transition state of the formamide-formimidic acid tautomerization. The resulting transition state geometry and barrier heights are in close agreement with coupled-cluster reference values. This work paves the way for highly accurate geometry optimization, molecular dynamics, or reaction path calculations.",
                "category": [
                    {
                        "@term": "physics.chem-ph",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cond-mat.str-el",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:53:55Z",
                "arxiv:primary_category": {
                    "@term": "physics.chem-ph"
                },
                "author": [
                    {
                        "name": "Jo S. Kurian"
                    },
                    {
                        "name": "Ankit Mahajan"
                    },
                    {
                        "name": "Sandeep Sharma"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13184v1",
                "title": "Profiling systematic uncertainties in Simulation-Based Inference with Factorizable Normalizing Flows",
                "updated": "2026-02-13T18:48:12Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13184v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13184v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Unbinned likelihood fits aim at maximizing the information one can extract from experimental data, yet their application in realistic statistical analyses is often hindered by the computational cost of profiling systematic uncertainties. Additionally, current machine learning-based inference methods are typically limited to estimating scalar parameters in a multidimensional space rather than full differential distributions. We propose a general framework for Simulation-Based Inference (SBI) that efficiently profiles nuisance parameters while measuring multivariate Distributions of Interest (DoI), defined as learnable invertible transformations of the feature space. We introduce Factorizable Normalizing Flows to model systematic variations as parametric deformations of a nominal density, preserving tractability without combinatorial explosion. Crucially, we develop an amortized training strategy that learns the conditional dependence of the DoI on nuisance parameters in a single optimization process, bypassing the need for repetitive training during the likelihood scan. This allows for the simultaneous extraction of the underlying distribution and the robust profiling of nuisances. The method is validated on a synthetic dataset emulating a high-energy physics measurement with multiple systematic sources, demonstrating its potential for unbinned, functional measurements in complex analyses.",
                "category": [
                    {
                        "@term": "hep-ph",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "physics.data-an",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "stat.ML",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:48:12Z",
                "arxiv:comment": "25 pages, 14 figures",
                "arxiv:primary_category": {
                    "@term": "hep-ph"
                },
                "author": [
                    {
                        "name": "Davide Valsecchi"
                    },
                    {
                        "name": "Mauro Doneg\u00e0"
                    },
                    {
                        "name": "Rainer Wallny"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13181v1",
                "title": "Selection of CMIP6 Models for Regional Precipitation Projection and Climate Change Assessment in the Jhelum and Chenab River Basins",
                "updated": "2026-02-13T18:41:40Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13181v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13181v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Effective water resource management depends on accurate projections of flows in water channels. For projected climate data, use of different General Circulation Models (GCM) simulates contrasting results. This study shows selection of GCM for the latest generation CMIP6 for hydroclimate change impact studies. Envelope based method was used for the selection, which includes components based on machine learning techniques, allowing the selection of GCMs without the need for in-situ reference data. According to our knowledge, for the first time, such a comparison was performed for the CMIP6 Shared Socioeconomic Pathway (SSP) scenarios data. In addition, the effect of climate change under SSP scenarios was studied, along with the calculation of extreme indices. Finally, GCMs were compared to quantify spatiotemporal differences between CMIP5 and CMIP6 data. Results provide NorESM2 LM, FGOALS g3 as selected models for the Jhelum and Chenab River. Highly vulnerable regions under the effect of climate change were highlighted through spatial maps, which included parts of Punjab, Jammu, and Kashmir. Upon comparison of CMIP5 and CMIP6, no discernible difference was found between the RCP and SSP scenarios precipitation projections. In the future, more detailed statistical comparisons could further reinforce the proposition.",
                "category": [
                    {
                        "@term": "physics.ao-ph",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:41:40Z",
                "arxiv:comment": "28 pages",
                "arxiv:primary_category": {
                    "@term": "physics.ao-ph"
                },
                "author": [
                    {
                        "name": "Saad Ahmed Jamal"
                    },
                    {
                        "name": "Ammara Nusrat"
                    },
                    {
                        "name": "Muhammad Azmat"
                    },
                    {
                        "name": "Muhammad Osama Nusrat"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13177v1",
                "title": "Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps",
                "updated": "2026-02-13T18:37:26Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13177v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13177v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).\n  Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \\in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization.",
                "category": [
                    {
                        "@term": "math.OC",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.DS",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-13T18:37:26Z",
                "arxiv:primary_category": {
                    "@term": "math.OC"
                },
                "author": [
                    {
                        "name": "Swati Gupta"
                    },
                    {
                        "name": "Jai Moondra"
                    },
                    {
                        "name": "Mohit Singh"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.13176v1",
                "title": "Monocular Markerless Motion Capture Enables Quantitative Assessment of Upper Extremity Reachable Workspace",
                "updated": "2026-02-13T18:36:27Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.13176v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.13176v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "To validate a clinically accessible approach for quantifying the Upper Extremity Reachable Workspace (UERW) using a single (monocular) camera and Artificial Intelligence (AI)-driven Markerless Motion Capture (MMC) for biomechanical analysis. Objective assessment and validation of these techniques for specific clinically oriented tasks are crucial for their adoption in clinical motion analysis. AI-driven monocular MMC reduces the barriers to adoption in the clinic and has the potential to reduce the overhead for analysis of this common clinical assessment. Nine adult participants with no impairments performed the standardized UERW task, which entails reaching targets distributed across a virtual sphere centered on the torso, with targets displayed in a VR headset. Movements were simultaneously captured using a marker-based motion capture system and a set of eight FLIR cameras. We performed monocular video analysis on two of these video camera views to compare a frontal and offset camera configurations. The frontal camera orientation demonstrated strong agreement with the marker-based reference, exhibiting a minimal mean bias of $0.61 \\pm 0.12$ \\% reachspace reached per octanct (mean $\\pm$ standard deviation). In contrast, the offset camera view underestimated the percent workspace reached ($-5.66 \\pm 0.45$ \\% reachspace reached). Conclusion: The findings support the feasibility of a frontal monocular camera configuration for UERW assessment, particularly for anterior workspace evaluation where agreement with marker-based motion capture was highest. The overall performance demonstrates clinical potential for practical, single-camera assessments. This study provides the first validation of monocular MMC system for the assessment of the UERW task. By reducing technical complexity, this approach enables broader implementation of quantitative upper extremity mobility assessment.",
                "category": {
                    "@term": "cs.CV",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-13T18:36:27Z",
                "arxiv:primary_category": {
                    "@term": "cs.CV"
                },
                "author": [
                    {
                        "name": "Seth Donahue"
                    },
                    {
                        "name": "J. D. Peiffer"
                    },
                    {
                        "name": "R. Tyler Richardson"
                    },
                    {
                        "name": "Yishan Zhong"
                    },
                    {
                        "name": "Shaun Q. Y. Tan"
                    },
                    {
                        "name": "Benoit Marteau"
                    },
                    {
                        "name": "Stephanie R. Russo"
                    },
                    {
                        "name": "May D. Wang"
                    },
                    {
                        "name": "R. James Cotton"
                    },
                    {
                        "name": "Ross Chafetz"
                    }
                ]
            }
        ]
    }
}