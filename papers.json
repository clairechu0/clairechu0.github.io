{
    "feed": {
        "@xmlns:opensearch": "http://a9.com/-/spec/opensearch/1.1/",
        "@xmlns:arxiv": "http://arxiv.org/schemas/atom",
        "@xmlns": "http://www.w3.org/2005/Atom",
        "id": "https://arxiv.org/api/GYXgOfCBQdW2qz4J20yiNWanGQo",
        "title": "arXiv Query: search_query=all:machine OR all:learning, OR all:AI, OR all:deep OR all:learning&id_list=&start=0&max_results=10",
        "updated": "2026-02-19T22:25:05Z",
        "link": {
            "@href": "https://arxiv.org/api/query?search_query=all:machine+OR+(all:learning,+OR+(all:AI,+OR+(all:deep+OR+all:learning)))&start=0&max_results=10&id_list=",
            "@type": "application/atom+xml"
        },
        "opensearch:itemsPerPage": "10",
        "opensearch:totalResults": "542380",
        "opensearch:startIndex": "0",
        "entry": [
            {
                "id": "http://arxiv.org/abs/2602.16712v1",
                "title": "One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation",
                "updated": "2026-02-18T18:59:57Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16712v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16712v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.",
                "category": {
                    "@term": "cs.RO",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-18T18:59:57Z",
                "arxiv:comment": "Project Page: https://zhenyuwei2003.github.io/OHRA/",
                "arxiv:primary_category": {
                    "@term": "cs.RO"
                },
                "author": [
                    {
                        "name": "Zhenyu Wei"
                    },
                    {
                        "name": "Yunchao Yao"
                    },
                    {
                        "name": "Mingyu Ding"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16710v1",
                "title": "EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data",
                "updated": "2026-02-18T18:59:05Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16710v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16710v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.",
                "category": {
                    "@term": "cs.RO",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-18T18:59:05Z",
                "arxiv:primary_category": {
                    "@term": "cs.RO"
                },
                "author": [
                    {
                        "name": "Ruijie Zheng"
                    },
                    {
                        "name": "Dantong Niu"
                    },
                    {
                        "name": "Yuqi Xie"
                    },
                    {
                        "name": "Jing Wang"
                    },
                    {
                        "name": "Mengda Xu"
                    },
                    {
                        "name": "Yunfan Jiang"
                    },
                    {
                        "name": "Fernando Casta\u00f1eda"
                    },
                    {
                        "name": "Fengyuan Hu"
                    },
                    {
                        "name": "You Liang Tan"
                    },
                    {
                        "name": "Letian Fu"
                    },
                    {
                        "name": "Trevor Darrell"
                    },
                    {
                        "name": "Furong Huang"
                    },
                    {
                        "name": "Yuke Zhu"
                    },
                    {
                        "name": "Danfei Xu"
                    },
                    {
                        "name": "Linxi Fan"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16709v1",
                "title": "Knowledge-Embedded Latent Projection for Robust Representation Learning",
                "updated": "2026-02-18T18:58:16Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16709v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16709v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.",
                "category": [
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "math.ST",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "stat.ME",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:58:16Z",
                "arxiv:primary_category": {
                    "@term": "cs.LG"
                },
                "author": [
                    {
                        "name": "Weijing Tang"
                    },
                    {
                        "name": "Ming Yuan"
                    },
                    {
                        "name": "Zongqi Xia"
                    },
                    {
                        "name": "Tianxi Cai"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16705v1",
                "title": "Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation",
                "updated": "2026-02-18T18:55:02Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16705v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16705v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.",
                "category": [
                    {
                        "@term": "cs.RO",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.CV",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:55:02Z",
                "arxiv:comment": "Project page: https://hero-humanoid.github.io/",
                "arxiv:primary_category": {
                    "@term": "cs.RO"
                },
                "author": [
                    {
                        "name": "Runpei Dong"
                    },
                    {
                        "name": "Ziyan Li"
                    },
                    {
                        "name": "Xialin He"
                    },
                    {
                        "name": "Saurabh Gupta"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16704v1",
                "title": "Reinforced Fast Weights with Next-Sequence Prediction",
                "updated": "2026-02-18T18:53:18Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16704v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16704v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.",
                "category": {
                    "@term": "cs.CL",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-18T18:53:18Z",
                "arxiv:primary_category": {
                    "@term": "cs.CL"
                },
                "author": [
                    {
                        "name": "Hee Seung Hwang"
                    },
                    {
                        "name": "Xindi Wu"
                    },
                    {
                        "name": "Sanghyuk Chun"
                    },
                    {
                        "name": "Olga Russakovsky"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16703v1",
                "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology",
                "updated": "2026-02-18T18:51:28Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16703v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16703v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a \"typical\" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.",
                "category": [
                    {
                        "@term": "cs.CY",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.AI",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:51:28Z",
                "arxiv:primary_category": {
                    "@term": "cs.CY"
                },
                "author": [
                    {
                        "name": "Shen Zhou Hong"
                    },
                    {
                        "name": "Alex Kleinman"
                    },
                    {
                        "name": "Alyssa Mathiowetz"
                    },
                    {
                        "name": "Adam Howes"
                    },
                    {
                        "name": "Julian Cohen"
                    },
                    {
                        "name": "Suveer Ganta"
                    },
                    {
                        "name": "Alex Letizia"
                    },
                    {
                        "name": "Dora Liao"
                    },
                    {
                        "name": "Deepika Pahari"
                    },
                    {
                        "name": "Xavier Roberts-Gaal"
                    },
                    {
                        "name": "Luca Righetti"
                    },
                    {
                        "name": "Joe Torres"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16700v1",
                "title": "The Role of Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems",
                "updated": "2026-02-18T18:46:58Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16700v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16700v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "In symmetric private information retrieval (SPIR), a user communicates with multiple servers to retrieve from them a message in a database, while not revealing the message index to any individual server (user privacy), and learning no additional information about the database (database privacy). We study the problem of SPIR on graph-replicated database systems, where each node of the graph represents a server and each link represents a message. Each message is replicated at exactly two servers; those at which the link representing the message is incident. To ensure database privacy, the servers share a set of common randomness, independent of the database and the user's desired message index. We study two cases of common randomness distribution to the servers: i) graph-replicated common randomness, and ii) fully-replicated common randomness. Given a graph-replicated database system, in i), we assign one randomness variable independently to every pair of servers sharing a message, while in ii), we assign an identical set of randomness variable to all servers, irrespective of the underlying graph. In both settings, our goal is to characterize the SPIR capacity, i.e., the maximum number of desired message symbols retrieved per downloaded symbol, and quantify the minimum amount of common randomness required to achieve the capacity. To this goal, in setting i), we derive a general lower bound on the SPIR capacity, and show it to be tight for path and regular graphs through a matching converse. Moreover, we establish that the minimum size of common randomness required for SPIR is equal to the message size. In setting ii), the SPIR capacity improves over the first, more restrictive setting. We show this through capacity lower bounds for a class of graphs, by constructing SPIR schemes from PIR schemes.",
                "category": [
                    {
                        "@term": "cs.IT",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.CR",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.NI",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "eess.SP",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:46:58Z",
                "arxiv:primary_category": {
                    "@term": "cs.IT"
                },
                "author": [
                    {
                        "name": "Shreya Meel"
                    },
                    {
                        "name": "Sennur Ulukus"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16698v1",
                "title": "Causality is Key for Interpretability Claims to Generalise",
                "updated": "2026-02-18T18:45:04Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16698v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16698v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies what an interpretability study can justify. Observations establish associations between model behaviour and internal components. Interventions (e.g., ablations or activation patching) support claims how these edits affect a behavioural metric (\\eg, average change in token probabilities) over a set of prompts. However, counterfactual claims -- i.e., asking what the model output would have been for the same prompt under an unobserved intervention -- remain largely unverifiable without controlled supervision. We show how causal representation learning (CRL) operationalises this hierarchy, specifying which variables are recoverable from activations and under what assumptions. Together, these motivate a diagnostic framework that helps practitioners select methods and evaluations matching claims to evidence such that findings generalise.",
                "category": {
                    "@term": "cs.LG",
                    "@scheme": "http://arxiv.org/schemas/atom"
                },
                "published": "2026-02-18T18:45:04Z",
                "arxiv:primary_category": {
                    "@term": "cs.LG"
                },
                "author": [
                    {
                        "name": "Shruti Joshi"
                    },
                    {
                        "name": "Aaron Mueller"
                    },
                    {
                        "name": "David Klindt"
                    },
                    {
                        "name": "Wieland Brendel"
                    },
                    {
                        "name": "Patrik Reizinger"
                    },
                    {
                        "name": "Dhanya Sridhar"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16697v1",
                "title": "Protecting the Undeleted in Machine Unlearning",
                "updated": "2026-02-18T18:44:21Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16697v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16697v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Machine unlearning aims to remove specific data points from a trained model, often striving to emulate \"perfect retraining\", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $\u03c9(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.",
                "category": [
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.DS",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:44:21Z",
                "arxiv:primary_category": {
                    "@term": "cs.LG"
                },
                "author": [
                    {
                        "name": "Aloni Cohen"
                    },
                    {
                        "name": "Refael Kohen"
                    },
                    {
                        "name": "Kobbi Nissim"
                    },
                    {
                        "name": "Uri Stemmer"
                    }
                ]
            },
            {
                "id": "http://arxiv.org/abs/2602.16696v1",
                "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
                "updated": "2026-02-18T18:42:29Z",
                "link": [
                    {
                        "@href": "https://arxiv.org/abs/2602.16696v1",
                        "@rel": "alternate",
                        "@type": "text/html"
                    },
                    {
                        "@href": "https://arxiv.org/pdf/2602.16696v1",
                        "@rel": "related",
                        "@type": "application/pdf",
                        "@title": "pdf"
                    }
                ],
                "summary": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
                "category": [
                    {
                        "@term": "q-bio.GN",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "cs.LG",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    },
                    {
                        "@term": "q-bio.QM",
                        "@scheme": "http://arxiv.org/schemas/atom"
                    }
                ],
                "published": "2026-02-18T18:42:29Z",
                "arxiv:primary_category": {
                    "@term": "q-bio.GN"
                },
                "author": [
                    {
                        "name": "Huan Souza"
                    },
                    {
                        "name": "Pankaj Mehta"
                    }
                ]
            }
        ]
    }
}